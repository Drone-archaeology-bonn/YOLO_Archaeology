{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df13bc1d-7786-4e51-a065-615f767a80e5",
   "metadata": {},
   "source": [
    "# What I did so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb7900-29e4-42da-b496-6a09326bb212",
   "metadata": {},
   "source": [
    "## Exploring and undersranding the orignal GeoJSON and Tiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3d6a2e-ae3b-4b3d-8afa-a10ae9b62676",
   "metadata": {},
   "source": [
    "- In geojson_exploration.ipynb I discovered that there are 4947 features in \"features_lidar.geojson\" \n",
    "- The Structure of \"features_lidar.geojson\" is: \\\n",
    "&emsp;    root: \\\n",
    "&emsp; &emsp;        type: \\\n",
    "&emsp; &emsp;        properties: \\\n",
    "&emsp; &emsp; &emsp;            ID_limes_main: \\\n",
    "&emsp; &emsp; &emsp;            name_limes_main: \\\n",
    "&emsp; &emsp; &emsp;            int_sitetype_limes: \\\n",
    "&emsp; &emsp; &emsp;            int_period_limes: \\\n",
    "&emsp; &emsp; &emsp;            int_period_limes: \\\n",
    "&emsp; &emsp; &emsp;            int_period_limes: \\\n",
    "&emsp; &emsp; &emsp;            int_detect_limes: \\\n",
    "&emsp; &emsp; &emsp;            Beschreibung: \\\n",
    "&emsp; &emsp; &emsp;            int_contribute: \\\n",
    "&emsp; &emsp; &emsp;            KDB_Link: \\\n",
    "&emsp; &emsp; &emsp;            int_period_fine: \\\n",
    "&emsp; &emsp; &emsp;            int_confidence_sitetyp: \\\n",
    "&emsp; &emsp; &emsp;            bibliography: \\\n",
    "&emsp; &emsp;        geometry: \\\n",
    "&emsp; &emsp; &emsp;            type: \\\n",
    "&emsp; &emsp; &emsp;            coordinates: \n",
    "\n",
    "- With the following contents: \n",
    "    - name_limes_main: {'', 'Hügelgräber am Mordhügel', 'NULL ', None}\n",
    "    - int_sitetype_limes: {'Bombentrichter', 'Grabhügel', 'Meilerpodium'}\n",
    "    - int_period_limes: {'Neuzeit', None, 'Römische Kaiserzeit', 'Vorrömische Eisenzeit', 'ZweiterWeltkrieg'}\n",
    "    - int_detect_limes: {'DOP 40 RLP', 'LiDAR-RLP'}\n",
    "    - Beschreibung: {'', 'Auf einem Höhenrücken westnordwestlich von Schalkenmehren liegen drei große Grabhügel, die 1860 geöffnet wurden. In einem der Hügel fand sich angeblich eine römische Aschenkiste (Funde verschollen).', 'Mertens Beinhausen 1', None, 'Statt der in der KDB erwähnten drei Hügel, sind nur zwei noch sichtbar. ', 'Zwei Hügel von 16 bzw. 18 Metern Durchmesser wurden 1935 bei Rodungsarbeiten entdeckt und sind heute völlig verebnet. Die römischen Bestattungen lagen als Nachbestattungen am Hügelrand. Eine Zuweisung der verschiedenen Bestattungen zu einem der beiden Hügel ist heute nicht mehr möglich. [1]', 'https://kulturdb.de/einobjekt.php?id=12214', 'https://kulturdb.de/einobjekt.php?id=12407', 'https://kulturdb.de/einobjekt.php?id=41125', 'https://kulturdb.de/einobjekt.php?id=4484'}\n",
    "    - int_contribute: {1, 4, 5, 6, 7, 9}\n",
    "    - KDB_Link: {'', 'NULLhttps://kulturdb.de/einobjekt.php?id=12616', None, 'https://kulturdb.de/einobjekt.php?id=12511', 'https://kulturdb.de/einobjekt.php?id=12537', 'https://kulturdb.de/einobjekt.php?id=12603', 'https://kulturdb.de/einobjekt.php?id=12607', 'https://kulturdb.de/einobjekt.php?id=12608', 'https://kulturdb.de/einobjekt.php?id=12609', 'https://kulturdb.de/einobjekt.php?id=12616', 'https://kulturdb.de/einobjekt.php?id=12618', 'https://kulturdb.de/einobjekt.php?id=12714', 'https://kulturdb.de/einobjekt.php?id=12821', 'https://kulturdb.de/einobjekt.php?id=12824', 'https://kulturdb.de/einobjekt.php?id=12881', 'https://kulturdb.de/einobjekt.php?id=12998', 'https://kulturdb.de/einobjekt.php?id=13000', 'https://kulturdb.de/einobjekt.php?id=14834', 'https://kulturdb.de/einobjekt.php?id=3640', 'https://kulturdb.de/einobjekt.php?id=41161', 'https://kulturdb.de/einobjekt.php?id=41217', 'https://kulturdb.de/einobjekt.php?id=41295', 'https://kulturdb.de/einobjekt.php?id=41366', 'https://kulturdb.de/einobjekt.php?id=41998', 'https://kulturdb.de/einobjekt.php?id=48608', 'https://kulturdb.de/einobjekt.php?id=5057', 'https://kulturdb.de/einobjekt.php?id=5555'}\n",
    "    - int_period_fine: {1, 17, None}\n",
    "    - int_confidence_sitetyp: {1, 17, 18, 2, 3, None}\n",
    "    - bibliography: {'Mertens 1980, 415\\n', 'Mertens 1980, 427', 'Mertens 1980, 430', 'Mertens 1980, 431', None, 'https://journals.ub.uni-heidelberg.de/index.php/fuabt/article/view/54692/54948'}\n",
    "\n",
    "- The properties that I use for creating my datasets are 'int_sitetype_limes' and 'coordinates'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335761e-7cbe-44b7-b403-77bbf853872b",
   "metadata": {},
   "source": [
    "# Data Organisation (Vulkaneifel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a634bd4-d36b-4523-a062-cc7645d3bad1",
   "metadata": {},
   "source": [
    "- We were given 2 folders \"split_images\" and \"split_features\", \"split_images\" containing the TIF images and \"split_features\" the corresponding features as GeoJSON files\n",
    "    - The structure of the \"split_images\" folder is \"split_images/x/y/x_y.tif\" for x = {0000,...,0216} and y = {0000,...,161} e.g. \"split_images/0000/0000/0000_0000.tif\" \n",
    "    - The structure of the \"split_features\" folder is \"split_features/z/\" for z = {00000,...,33695} contains 4 files \"z.dbf\", \"z.prj\", \"z.shp\", \"z.shx\" e.g. \"split_features/00000/00000.shp\"\n",
    "- I renamed the images in a way that each image matches the structure of it's corresponding feature in a new folder \"Images\"\n",
    "- I converted the Shapefiles of the features into GeoJSON files and saved them in \"GeoJSON\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663933a3-018f-4f4f-b182-ef85e47531ee",
   "metadata": {},
   "source": [
    "# Extracting the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d58e63-e9d1-42ff-bb4b-742ccd69bd37",
   "metadata": {},
   "source": [
    "- YOLOv5 specifications for labels are:\n",
    "    - One row per object\n",
    "    - Each row is 'class x_center y_center width height' format\n",
    "    - Box coordinates must be in normalized xywh format (from 0 - 1)\n",
    "    - Class numbers are zero-indexed \n",
    "- The classes are:\n",
    "    - 0: Bombentrichter\n",
    "    - 1: Grabhügel\n",
    "    - 2: Meilerpodium\n",
    "- x_center and y_center are calculated by: sum(x)/len(points), where x and points are lists containing all points of one object\n",
    "- width is calculated by: max(x) - min(x), and height by: max(y) - min(y)\n",
    "- I than save each object in one image as a new row in a TXT file in \"Labels\" e.g. Labels/00000.txt\"\n",
    "- I check how many instances of each class exist in the Label files:\n",
    "    - Bombentrichter:  3375 about 19.606%\n",
    "    - Grabhuegel:  1632 about 9.481%\n",
    "    - Meilerpodium:  12207 about 70.913%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0851e-c32f-499c-ab66-6a36de3296e9",
   "metadata": {},
   "source": [
    "# Creation of \"dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a1754-fbd6-4a68-9c26-1a5ee97f5831",
   "metadata": {},
   "source": [
    "- We were given a total of 35154 images, at first I used all images to create the dataset\n",
    "- 70% for training (24607 images), 15% for validation (5273 images) and 15% for test (5274 images)\n",
    "- The images and corresponding features got moved over to: \\\n",
    "&emsp; dataset/ \\\n",
    "&emsp;&emsp; images/ \\\n",
    "&emsp;&emsp;&emsp; train/ \\\n",
    "&emsp;&emsp;&emsp; val/ \\\n",
    "&emsp;&emsp;&emsp; test/ \\\n",
    "&emsp;&emsp; labels/ \\\n",
    "&emsp;&emsp;&emsp; train/ \\\n",
    "&emsp;&emsp;&emsp; val/ \\\n",
    "&emsp;&emsp;&emsp; test/ \n",
    "- This dataset contained 94% background images\n",
    "- After training with the yolo5s and yolov5x models it became clear that this dataset contained to many images that are without any objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e2dbb6-8aec-4bc6-9cdd-9127447949fe",
   "metadata": {},
   "source": [
    "# Creation of \"9_background_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e4ab8-c913-4ee1-bb26-990a1d49917b",
   "metadata": {},
   "source": [
    "- First of all I divided the images into two folders \"Labeled_images\" and \"No_label_images\"\n",
    "- I then created a folder \"Dataset_images\" that contains all the labeled images and about 9% of the total images in it are background images, that are picked randomly\n",
    "- Now the new dataset contain out of 2324 images\n",
    "- Since the new dataset is much smaller I decided to not put any images into a test set\n",
    "- 80% for training (1859 images) and 20% for validation(465 images)\n",
    "- The images and corresponding features got moved over to: \\\n",
    "&emsp; 9_background_dataset/ \\\n",
    "&emsp;&emsp; images/ \\\n",
    "&emsp;&emsp;&emsp; train/ \\\n",
    "&emsp;&emsp;&emsp; val/ \\\n",
    "&emsp;&emsp; labels/ \\\n",
    "&emsp;&emsp;&emsp; train/ \\\n",
    "&emsp;&emsp;&emsp; val/ \n",
    "- The training with the yolov4s model gave dramatically improved result compared to the training results with \"dataset\"\n",
    "- The traing on the yolov5x model was even better than on the yolov5s model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5199facf-193e-414c-8cc9-d4117037557a",
   "metadata": {},
   "source": [
    "# YOLOv5 results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99dd80b-50e3-4a6a-b91b-3229891fca5a",
   "metadata": {},
   "source": [
    "- exp13: python train.py --img 224 --batch 128 --epochs 300 --data ./dataset/dataset.yaml --weights yolov5s.pt\n",
    "- exp14: python train.py --img 224 --batch 128 --epochs 300 --data ./dataset/dataset.yaml --weights yolov5x.pt\n",
    "- exp16: python train.py --img 224 --batch 128 --epochs 300 --data ./9_background_dataset/9_background_dataset.yaml --weights yolov5s.pt\n",
    "- exp17: python train.py --img 224 --batch 128 --epochs 300 --data ./9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp18: python train.py --hyp hyp.no-augmentation.yaml --img 224 --batch 128 --epochs 300 --data ./9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp19: python train.py --hyp hyp.no-augmentation.yaml --img 224 --batch 128 --epochs 300 --data ./dataset/dataset.yaml --weights yolov5x.pt\n",
    "- exp20: python train.py --img 224 --batch 64 --epochs 300 --data ./9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp21: python train.py --hyp hyp.learing-rate-005.yaml --img 224 --batch 64 --epochs 300 --data ./9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp22: python train.py --hyp hyp.learing-rate-001.yaml --img 224 --batch 64 --epochs 300 --data ./9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp23: python train.py --hyp hyp.fail.yaml --img 224 --batch 64 --epochs 300 --data ./9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp24: python train.py --hyp hyp.fail.yaml --img 200 --batch 64 --epochs 300 --data ./9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp25: python train.py --hyp hyp.learing-rate-005.yaml --img 224 --batch 124 --epochs 300 --data ./9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp26: python train.py --hyp hyp.learing-rate-004.yaml --img 224 --batch 124 --epochs 300 --data ./9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp27: python train.py --hyp hyp.learing-rate-006.yaml --img 224 --batch 124 --epochs 300 --data ./9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp28: python train.py --hyp hyp.modify_images.yaml --img 200 --batch 128 --epochs 300 --data ../9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp31: python train.py --img 224 --batch 200 --epochs 300 --data ./9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp32: python train.py --hyp hyp.learing-rate-001.yaml --img 224 --batch 128 --epochs 300 --data ../9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp33: python train.py --hyp hyp.learing-rate-002.yaml --img 224 --batch 128 --epochs 300 --data ../9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp34: python train.py --hyp hyp.learing-rate-003.yaml --img 224 --batch 128 --epochs 300 --data ../9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp35: python train.py --hyp hyp.learing-rate-004.yaml --img 224 --batch 128 --epochs 300 --data ../9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp36: python train.py --hyp hyp.learing-rate-005.yaml --img 224 --batch 128 --epochs 300 --data ../9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp37: python train.py --hyp hyp.learing-rate-006.yaml --img 224 --batch 128 --epochs 300 --data ../9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp38: python train.py --hyp hyp.learing-rate-007.yaml --img 224 --batch 128 --epochs 300 --data ../9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp39: python train.py --hyp hyp.learing-rate-008.yaml --img 224 --batch 128 --epochs 300 --data ../9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp40: python train.py --hyp hyp.learing-rate-009.yaml --img 224 --batch 128 --epochs 300 --data ../9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "- exp41: python train.py --hyp hyp.learing-rate-011.yaml --img 224 --batch 128 --epochs 300 --data ../9_background_dataset/9_background_dataset.yaml --weights yolov5x.pt\n",
    "\n",
    "The best results so far were achived using a batch size of 64 with the yolov5x model using a learning rate of 0.005 and the image augmentation in \"hyp.scratch-low.yaml\"\n",
    "-> epx17 & exp21 show the best results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c4bf3b-6367-4296-a55d-bd3152e12177",
   "metadata": {},
   "source": [
    "# How could we improve the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5903915e-0069-4f92-9f56-f9abc054201c",
   "metadata": {},
   "source": [
    "- Ideas:\n",
    "    - There are still a bunch of completely and mostly black images, it would be good to fremove at least the compleately balck images\n",
    "    - It seemes that the given map is not perfect (meaning there are objects on the map that aren't labeled on the GeoJSON). The confusion matrix of the result shows that there are difficulties in differentiating the objects and the background from each other.\n",
    "    - Try out the command of exp21 but with a batch size of 128\n",
    "    - Try diffrent learing rates close to 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed7aef-b975-4369-9e39-8a63b8845573",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29ac27-d56e-4a30-a7c9-6d32c85d2c90",
   "metadata": {},
   "source": [
    "- yolov5 results.png:\n",
    "    - box_loss:     bounding box regression loss (Mean Squared Error).\n",
    "    - obj_loss:     the confidence of object presence is the objectness loss.\n",
    "    - cls_loss:     the classification loss (Cross Entropy).\n",
    "    - Precision:    measures how much of the bbox predictions are correct ( True positives / (True positives + False positives)).\n",
    "    - Recall:       measures how much of the true bbox were correctly predicted ( True positives / (True positives + False negatives)).\n",
    "    - mAP_0.5:      is the mean Average Precision (mAP) at IoU (Intersection over Union) threshold of 0.5.\n",
    "    - mAP_0.5:0.95: is the average mAP over different IoU thresholds, ranging from 0.5 to 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c556b78-d055-4e84-a5d1-41adcf865fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
